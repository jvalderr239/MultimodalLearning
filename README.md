# MultimodalLearning
Designed and trained a fusion network relying on the AlexNet architecture model to accurately predict the emotions of a speaker based on their facial expressions and vocal tone. Model was evaluated against accuracy vs training size, facial recognition-only accuracy, vocal tone-only accuracy and hyper parameter tuning effects.
